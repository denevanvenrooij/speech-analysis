{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'extraction_functions_praat' from '/home/dene/rp2/extraction_functions_praat.py'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import extraction_functions_praat\n",
    "importlib.reload(extraction_functions_praat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import *\n",
    "import pandas as pd\n",
    "from extraction_functions_praat import (\n",
    "    PP_f0_mean, PP_f0_median, PP_f0_sd,\n",
    "    PP_f0_mean_murton, PP_f0_median_murton, PP_f0_sd_murton, \n",
    "    PP_jitter, PP_jitter_murton,\n",
    "    PP_lh_ratio, PP_lh_ratio_murton,\n",
    "    PP_cpp_mean_murton, PP_cpp_median_murton, PP_cpp_sd_murton,\n",
    "    PP_max_phonation,\n",
    "    PP_harmonics_to_noise, PP_harmonics_to_noise_murton,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAILABLE_FEATURES = [\n",
    "    'PP_F0', 'PP_F02', 'PP_F0_SD', \n",
    "    'PP_F0_M', 'PP_F02_M', 'PP_F0_SD_M', \n",
    "    'PP_JIT', 'PP_JIT_M',\n",
    "    'PP_LHR', 'PP_LHR_M',\n",
    "    'PP_CPP_M', 'PP_CPP_M2', 'PP_CPP_SD_M',\n",
    "    'PP_MAX_PH',\n",
    "    'PP_HNR', 'PP_HNR_M',\n",
    "] ## add more\n",
    "\n",
    "selected_features_dict = {\n",
    "    'PP_F0': True, 'PP_F02':True, 'PP_F0_SD': True, \n",
    "    'PP_F0_M': True, 'PP_F02_M':True, 'PP_F0_SD_M': True, \n",
    "    'PP_JIT': True, 'PP_JIT_M': True,\n",
    "    'PP_LHR': True, 'PP_LHR_M': True,\n",
    "    'PP_CPP_M': True, 'PP_CPP_M2': True, 'PP_CPP_SD_M':True,\n",
    "    'PP_MAX_PH': True,\n",
    "    'PP_HNR': True, 'PP_HNR_M': True,\n",
    "} ## enable the ones you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_vowels(audio_file, selected_features, segment_length, f0_min, f0_max, jitter_type):\n",
    "    extracted_features = {}\n",
    "    \n",
    "    if 'PP_F0' in selected_features:\n",
    "        extracted_features['PP_F0'] = PP_f0_mean(audio_file, f0_min=f0_min, f0_max=f0_max)\n",
    "    if 'PP_F0_M' in selected_features:\n",
    "        extracted_features['PP_F0_M'] = PP_f0_mean_murton(audio_file, f0_min=f0_min, f0_max=f0_max)\n",
    "    if 'PP_F0_SD' in selected_features:\n",
    "        extracted_features['PP_F0_SD'] = PP_f0_sd(audio_file, f0_min=f0_min, f0_max=f0_max)\n",
    "    if 'PP_F0_SD_M' in selected_features:\n",
    "        extracted_features['PP_F0_SD_M'] = PP_f0_sd_murton(audio_file, f0_min=f0_min, f0_max=f0_max)\n",
    "    if 'PP_JIT' in selected_features:\n",
    "        jitter_values = PP_jitter(audio_file, f0_min=f0_min, f0_max=f0_max, type=jitter_type)\n",
    "        if jitter_type == 'all':\n",
    "            extracted_features['PP_JIT_local'] = jitter_values[0]\n",
    "            extracted_features['PP_JIT_abs'] = jitter_values[1]\n",
    "            extracted_features['PP_JIT_rap'] = jitter_values[2]\n",
    "            extracted_features['PP_JIT_ppq5'] = jitter_values[3]\n",
    "            extracted_features['PP_JIT_ddp'] = jitter_values[4]\n",
    "        else:\n",
    "            extracted_features[f'PP_JIT_{jitter_type}'] = jitter_values\n",
    "    if 'PP_JIT_M' in selected_features:\n",
    "        jitter_values = PP_jitter_murton(audio_file, segment_length=segment_length, f0_min=f0_min, f0_max=f0_max, type=jitter_type)\n",
    "        if jitter_type == 'all':\n",
    "            extracted_features['PP_JIT_M_local'] = jitter_values[0]\n",
    "            extracted_features['PP_JIT_M_abs'] = jitter_values[1]\n",
    "            extracted_features['PP_JIT_M_rap'] = jitter_values[2]\n",
    "            extracted_features['PP_JIT_M_ppq5'] = jitter_values[3]\n",
    "            extracted_features['PP_JIT_M_ddp'] = jitter_values[4]\n",
    "        else:\n",
    "            extracted_features[f'PP_JIT_M_{jitter_type}'] = jitter_values\n",
    "    if 'PP_LHR' in selected_features:\n",
    "        extracted_features['PP_LHR'] = PP_lh_ratio(audio_file)\n",
    "    if 'PP_LHR_M' in selected_features:\n",
    "        extracted_features['PP_LHR_M'] = PP_lh_ratio_murton(audio_file, segment_length=segment_length)\n",
    "    if 'PP_CPP_M' in selected_features:\n",
    "        extracted_features['PP_CPP_M'] = PP_cpp_mean_murton(audio_file)\n",
    "    if 'PP_CPP_M2' in selected_features:\n",
    "        extracted_features['PP_CPP_M2'] = PP_cpp_median_murton(audio_file)\n",
    "    if 'PP_CPP_SD_M' in selected_features:\n",
    "        extracted_features['PP_CPP_SD_M'] = PP_cpp_sd_murton(audio_file)\n",
    "    if 'PP_HNR' in selected_features:\n",
    "        extracted_features['PP_HNR'] = PP_harmonics_to_noise(audio_file)\n",
    "    if 'PP_HNR_M' in selected_features:\n",
    "        extracted_features['PP_HNR_M'] = PP_harmonics_to_noise_murton(audio_file, segment_length=segment_length)\n",
    "            \n",
    "    return extracted_features\n",
    "\n",
    "\n",
    "def extract_features_mpt(audio_file, selected_features, silence_threshold):\n",
    "    extracted_features = {}\n",
    "    \n",
    "    if 'PP_MAX_PH' in selected_features:\n",
    "        extracted_features['PP_MAX_PH'] = PP_max_phonation(audio_file, silence_threshold)\n",
    "            \n",
    "    return extracted_features\n",
    "\n",
    "\n",
    "def extract_features_sentences(audio_file, selected_features, f0_min, f0_max):\n",
    "    extracted_features = {}\n",
    "    \n",
    "    if 'PP_F02' in selected_features:\n",
    "        extracted_features['PP_F02'] = PP_f0_median(audio_file, f0_min=f0_min, f0_max=f0_max)    \n",
    "    if 'PP_F02_M' in selected_features:\n",
    "        extracted_features['PP_F02_M'] = PP_f0_median_murton(audio_file, f0_min=f0_min, f0_max=f0_max)  \n",
    "    if 'PP_F0_SD' in selected_features:\n",
    "        extracted_features['PP_F0_SD'] = PP_f0_sd(audio_file, f0_min=f0_min, f0_max=f0_max)\n",
    "    if 'PP_F0_SD_M' in selected_features:\n",
    "        extracted_features['PP_F0_SD_M'] = PP_f0_sd_murton(audio_file, f0_min=f0_min, f0_max=f0_max)\n",
    "    if 'PP_CPP_M' in selected_features:\n",
    "        extracted_features['PP_CPP_M'] = PP_cpp_mean_murton(audio_file)\n",
    "    if 'PP_CPP_M2' in selected_features:\n",
    "        extracted_features['PP_CPP_M2'] = PP_cpp_median_murton(audio_file)\n",
    "    if 'PP_CPP_SD_M' in selected_features:\n",
    "        extracted_features['PP_CPP_SD_M'] = PP_cpp_sd_murton(audio_file)\n",
    "                        \n",
    "    return extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_files_vowels(directory, selected_features, segment_length, f0_min, f0_max, jitter_type):\n",
    "    patient_dfs = {}\n",
    "\n",
    "    files = [file for d in directory for file in d.rglob('*') if file.is_file()]\n",
    "\n",
    "    for file in files:\n",
    "        filename = file.stem.replace(\"_pre\", \"\")\n",
    "        parts = filename.split(\"_\")\n",
    "        if len(parts) != 4:\n",
    "            print(f\"Unexpected named audio file: {file}\")\n",
    "            continue\n",
    "\n",
    "        patient_id, day, exercise, take_letter = parts\n",
    "\n",
    "        features = {}\n",
    "        file_path = str(file)\n",
    "        \n",
    "        if exercise == 'VOW':\n",
    "            if directory == best_segments_dir:\n",
    "                if file_path[-1].isdigit(): \n",
    "                    continue ## we do not analyze the best segment of the entire vowel exercise, only of the best segments\n",
    "                if file_path[-1].isalpha():\n",
    "                    features = extract_features_vowels(file_path, selected_features, f0_min, f0_max, jitter_type)\n",
    "            else:\n",
    "                features = extract_features_vowels(file_path, selected_features, segment_length, f0_min, f0_max, jitter_type)\n",
    "        \n",
    "        if features:    \n",
    "            df_entry = {'day': int(day), **features}       \n",
    "            df_key = (patient_id, take_letter, exercise)\n",
    "            if df_key not in patient_dfs:\n",
    "                patient_dfs[df_key] = pd.DataFrame(columns=['day'] + list(features.keys()))\n",
    "            patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
    "        \n",
    "        for key, df in patient_dfs.items():\n",
    "            patient_dfs[key] = df.sort_values(by='day', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        for (patient_id, take_letter, exercise), df in patient_dfs.items():\n",
    "            file_name = f\"{patient_id}_{exercise}_{take_letter}.csv\"\n",
    "            file_path = features_dir / exercise / patient_id / file_name\n",
    "\n",
    "            df.to_csv(file_path, index=False)\n",
    "\n",
    "def process_audio_files_mpt(directory, selected_features, silence_threshold):\n",
    "    patient_dfs = {}\n",
    "\n",
    "    files = [file for d in directory for file in d.rglob('*') if file.is_file()]\n",
    "\n",
    "    for file in files:\n",
    "        filename = file.stem.replace(\"_pre\", \"\")\n",
    "        parts = filename.split(\"_\")\n",
    "        if len(parts) != 4:\n",
    "            print(f\"Unexpected named audio file: {file}\")\n",
    "            continue\n",
    "\n",
    "        patient_id, day, exercise, take_letter = parts\n",
    "\n",
    "        features = {}\n",
    "        file_path = str(file)\n",
    "        \n",
    "        if exercise == 'MPT':\n",
    "            features = extract_features_mpt(file_path, selected_features, silence_threshold)\n",
    "            \n",
    "        if features:            \n",
    "            df_entry = {'day': int(day), **features}    \n",
    "            df_key = (patient_id, take_letter, exercise)\n",
    "            if df_key not in patient_dfs:\n",
    "                patient_dfs[df_key] = pd.DataFrame(columns=['day'] + list(features.keys()))\n",
    "            patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
    "            \n",
    "        for key, df in patient_dfs.items():\n",
    "            patient_dfs[key] = df.sort_values(by='day', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        for (patient_id, take_letter, exercise), df in patient_dfs.items():\n",
    "            file_name = f\"{patient_id}_{exercise}_{take_letter}.csv\"\n",
    "            file_path = features_dir / exercise / patient_id / file_name\n",
    "\n",
    "            df.to_csv(file_path, index=False)\n",
    "\n",
    "def process_audio_files_sentences(directory, selected_features, f0_min, f0_max):\n",
    "    patient_dfs = {}\n",
    "\n",
    "    files = [file for d in directory for file in d.rglob('*') if file.is_file()]\n",
    "\n",
    "    for file in files:\n",
    "        filename = file.stem.replace(\"_pre\", \"\")\n",
    "        parts = filename.split(\"_\")\n",
    "        if len(parts) != 4:\n",
    "            print(f\"Unexpected named audio file: {file}\")\n",
    "            continue\n",
    "\n",
    "        patient_id, day, exercise, take_letter = parts\n",
    "        \n",
    "        features = {}\n",
    "        file_path = str(file)\n",
    "        \n",
    "        if exercise == 'SEN':\n",
    "            features = extract_features_sentences(file_path, selected_features, f0_min, f0_max)\n",
    "            \n",
    "        if features:\n",
    "            df_entry = {'day': int(day), **features}    \n",
    "            df_key = (patient_id, take_letter, exercise)\n",
    "            if df_key not in patient_dfs:\n",
    "                patient_dfs[df_key] = pd.DataFrame(columns=['day'] + list(features.keys()))\n",
    "            patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
    "        \n",
    "        for key, df in patient_dfs.items():\n",
    "            patient_dfs[key] = df.sort_values(by='day', ascending=True).reset_index(drop=True)\n",
    "            \n",
    "        for (patient_id, take_letter, exercise), df in patient_dfs.items():\n",
    "            file_name = f\"{patient_id}_{exercise}_{take_letter}.csv\"\n",
    "            file_path = features_dir / exercise / patient_id / file_name\n",
    "\n",
    "            df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1202/2900849528.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
      "/tmp/ipykernel_1202/2900849528.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
      "/tmp/ipykernel_1202/2900849528.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
      "/tmp/ipykernel_1202/2900849528.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
      "/tmp/ipykernel_1202/2900849528.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
      "/tmp/ipykernel_1202/2900849528.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
      "/tmp/ipykernel_1202/2900849528.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
      "/tmp/ipykernel_1202/2900849528.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
      "/tmp/ipykernel_1202/2900849528.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
      "/tmp/ipykernel_1202/2900849528.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
      "/tmp/ipykernel_1202/2900849528.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
      "/tmp/ipykernel_1202/2900849528.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
      "/tmp/ipykernel_1202/2900849528.py:104: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "dir_to_run_vowels = [\n",
    "    audio_dir,\n",
    "    segments_dir,\n",
    "    # best_segments_dir, ## will not use the best segments for now, since I might use the middle of a vowel segment (Murton 2023)\n",
    "]\n",
    "dir_to_run_mpt = [audio_dir, segments_dir]\n",
    "dir_to_run_sentences = [audio_dir, segments_dir]\n",
    "\n",
    "process_audio_files_vowels(\n",
    "    directory=dir_to_run_vowels,\n",
    "    selected_features=selected_features_dict,\n",
    "    segment_length=1.0,\n",
    "    f0_min=60, f0_max=300, \n",
    "    jitter_type='all') ## choose from 'local' 'abs' 'rap' 'ppq5' 'ddp' 'all'\n",
    "\n",
    "process_audio_files_mpt(\n",
    "    directory=dir_to_run_mpt,\n",
    "    selected_features=selected_features_dict,\n",
    "    silence_threshold=50) ## choose from 'local' 'abs' 'rap' 'ppq5' 'ddp' 'all'\n",
    "\n",
    "process_audio_files_sentences(\n",
    "    directory=dir_to_run_sentences,\n",
    "    selected_features=selected_features_dict,\n",
    "    f0_min=60, f0_max=300) ## choose from 'local' 'abs' 'rap' 'ppq5' 'ddp' 'all'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rp2",
   "language": "python",
   "name": "rp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
