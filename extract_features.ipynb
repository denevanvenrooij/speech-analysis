{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'features' from '/home/dene/rp2/features.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import extraction_functions_praat\n",
    "import features\n",
    "importlib.reload(extraction_functions_praat)\n",
    "importlib.reload(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "2025-04-03 13:41:51.289957: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-03 13:41:51.767201: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743680512.018172     895 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743680512.079981     895 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743680512.458225     895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743680512.458345     895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743680512.458349     895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743680512.458351     895 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-03 13:41:52.494599: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from paths import *\n",
    "from features import *\n",
    "from extraction_functions_praat import *\n",
    "from extraction_functions_disvoice import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_VOW(audio_file, selected_features, segment_length, f0_min, f0_max, point_step, time_step, max_frequency, num_formants):\n",
    "    extracted_features = {}\n",
    "    \n",
    "    if 'PP_F0' in selected_features:\n",
    "        extracted_features['PP_F0'] = PP_f0_mean(audio_file, f0_min=f0_min, f0_max=f0_max)\n",
    "    if 'PP_F0_M' in selected_features:\n",
    "        extracted_features['PP_F0_M'] = PP_f0_mean_murton(audio_file, f0_min=f0_min, f0_max=f0_max)\n",
    "    if 'PP_F0_SD' in selected_features:\n",
    "        extracted_features['PP_F0_SD'] = PP_f0_sd(audio_file, f0_min=f0_min, f0_max=f0_max)\n",
    "    if 'PP_F0_SD_M' in selected_features:\n",
    "        extracted_features['PP_F0_SD_M'] = PP_f0_sd_murton(audio_file, f0_min=f0_min, f0_max=f0_max)\n",
    "\n",
    "    if 'PP_LHR' in selected_features:\n",
    "        extracted_features['PP_LHR'] = PP_lh_ratio(audio_file)\n",
    "    if 'PP_LHR_M' in selected_features:\n",
    "        extracted_features['PP_LHR_M'] = PP_LH_ratio_murton(audio_file, segment_length=segment_length)\n",
    "\n",
    "    if 'PP_CPP_M' in selected_features:\n",
    "        extracted_features['PP_CPP_M'] = PP_CPP_mean_murton(audio_file)\n",
    "    if 'PP_CPP_M2' in selected_features:\n",
    "        extracted_features['PP_CPP_M2'] = PP_CPP_median_murton(audio_file)\n",
    "    if 'PP_CPP_SD_M' in selected_features:\n",
    "        extracted_features['PP_CPP_SD_M'] = PP_CPP_sd_murton(audio_file)\n",
    "\n",
    "    if 'PP_HNR' in selected_features:\n",
    "        extracted_features['PP_HNR'] = PP_harmonics_to_noise(audio_file)\n",
    "    if 'PP_HNR_M' in selected_features:\n",
    "        extracted_features['PP_HNR_M'] = PP_harmonics_to_noise_murton(audio_file, segment_length=segment_length)\n",
    "\n",
    "    if 'PP_JIT' in selected_features:\n",
    "        jitter_values = PP_jitter(audio_file, f0_min=f0_min, f0_max=f0_max) \n",
    "        for feature in jitter_feature_selection:\n",
    "            if feature in jitter_feature_indices:\n",
    "                feature_idx = jitter_feature_indices[feature]            \n",
    "                extracted_features[f'PP_JIT_{feature}'] = jitter_values[feature_idx]  \n",
    "    if 'PP_JIT_M' in selected_features:\n",
    "        jitter_values = PP_jitter_murton(audio_file, segment_length=segment_length, f0_min=f0_min, f0_max=f0_max) \n",
    "        for feature in jitter_feature_selection:\n",
    "            if feature in jitter_feature_indices:\n",
    "                feature_idx = jitter_feature_indices[feature]            \n",
    "                extracted_features[f'PP_JIT_M_{feature}'] = jitter_values[feature_idx]    \n",
    "\n",
    "    if 'PP_SHI' in selected_features:\n",
    "        shimmer_values = PP_shimmer(audio_file, f0_min=f0_min, f0_max=f0_max) \n",
    "        for feature in shimmer_feature_selection:\n",
    "            if feature in shimmer_feature_indices:\n",
    "                feature_idx = shimmer_feature_indices[feature]            \n",
    "                extracted_features[f'PP_SHI_{feature}'] = shimmer_values[feature_idx]\n",
    "    if 'PP_SHI_M' in selected_features:\n",
    "        shimmer_values = PP_shimmer_murton(audio_file, segment_length=segment_length, f0_min=f0_min, f0_max=f0_max) \n",
    "        for feature in shimmer_feature_selection:\n",
    "            if feature in shimmer_feature_indices:\n",
    "                feature_idx = shimmer_feature_indices[feature]            \n",
    "                extracted_features[f'PP_SHI_M_{feature}'] = shimmer_values[feature_idx]\n",
    "    \n",
    "    if 'PP_GF_MEA' in selected_features:\n",
    "        mean_glottal_formant_values = PP_glottal_formants_mean(audio_file, f0_min=f0_min, f0_max=f0_max, point_step=point_step, max_frequency=max_frequency, num_formants=num_formants)\n",
    "        for i in range(len(mean_glottal_formant_values)): \n",
    "            extracted_features[f'PP_GF{i+1}_MEA'] = mean_glottal_formant_values[i]\n",
    "    if 'PP_GF_MED' in selected_features:\n",
    "        median_glottal_formant_values = PP_glottal_formants_median(audio_file, f0_min=f0_min, f0_max=f0_max, point_step=point_step, max_frequency=max_frequency, num_formants=num_formants)\n",
    "        for i in range(len(median_glottal_formant_values)): \n",
    "            extracted_features[f'PP_GF{i+1}_MED'] = median_glottal_formant_values[i]            \n",
    "    if 'PP_GF_SD' in selected_features:\n",
    "        sd_glottal_formant_values = PP_glottal_formants_sd(audio_file, f0_min=f0_min, f0_max=f0_max, point_step=point_step, max_frequency=max_frequency, num_formants=num_formants)\n",
    "        for i in range(len(sd_glottal_formant_values)): \n",
    "            extracted_features[f'PP_GF{i+1}_SD'] = sd_glottal_formant_values[i]        \n",
    "\n",
    "    if 'PP_F_MEA' in selected_features:\n",
    "        mean_formant_values = PP_formants_mean(audio_file, time_step=time_step, max_frequency=max_frequency, num_formants=num_formants)\n",
    "        for i in range(len(mean_formant_values)): \n",
    "            extracted_features[f'PP_F{i+1}_MEA'] = mean_formant_values[i]\n",
    "    if 'PP_F_MED' in selected_features:\n",
    "        median_formant_values = PP_formants_median(audio_file, time_step=time_step, max_frequency=max_frequency, num_formants=num_formants)\n",
    "        for i in range(len(median_formant_values)): \n",
    "            extracted_features[f'PP_F{i+1}_MED'] = median_formant_values[i]            \n",
    "    if 'PP_F_SD' in selected_features:\n",
    "        sd_formant_values = PP_formants_sd(audio_file, time_step=time_step, max_frequency=max_frequency, num_formants=num_formants)\n",
    "        for i in range(len(sd_formant_values)): \n",
    "            extracted_features[f'PP_F{i+1}_SD'] = sd_formant_values[i]\n",
    "    \n",
    "    if 'DV_PRO' in selected_features:\n",
    "        prosody_features = DV_prosody(audio_file)\n",
    "        for feature in prosody_features.columns:\n",
    "            extracted_features[f'DV_PRO_{feature}'] = prosody_features[feature].values[0]\n",
    "    if 'DV_PHO' in selected_features: \n",
    "        phonation_features = DV_phonation(audio_file)\n",
    "        for feature in phonation_features.columns:\n",
    "            extracted_features[f'DV_PHO_{feature}'] = phonation_features[feature].values[0]     \n",
    "    if 'DV_GLO' in selected_features:\n",
    "        glottal_features = DV_glottal(audio_file)\n",
    "        for feature in glottal_features.columns:\n",
    "            extracted_features[f'DV_GLO_{feature}'] = glottal_features[feature].values[0]        \n",
    "            \n",
    "    return extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_SEN(audio_file, selected_features, f0_min, f0_max, silence_threshold, min_silence_duration, segment_length, num_coefficients, time_step, max_frequency, num_formants):\n",
    "    extracted_features = {}\n",
    "    \n",
    "    if 'PP_F0' in selected_features:\n",
    "        extracted_features['PP_F0'] = PP_f0_median(audio_file, f0_min=f0_min, f0_max=f0_max)    \n",
    "    if 'PP_F0_M' in selected_features:\n",
    "        extracted_features['PP_F0_M'] = PP_f0_median_murton(audio_file, f0_min=f0_min, f0_max=f0_max)  \n",
    "    if 'PP_F0_SD' in selected_features:\n",
    "        extracted_features['PP_F0_SD'] = PP_f0_sd(audio_file, f0_min=f0_min, f0_max=f0_max)\n",
    "    if 'PP_F0_SD_M' in selected_features:\n",
    "        extracted_features['PP_F0_SD_M'] = PP_f0_sd_murton(audio_file, f0_min=f0_min, f0_max=f0_max)\n",
    "        \n",
    "    if 'PP_CPP_M' in selected_features:\n",
    "        extracted_features['PP_CPP_M'] = PP_CPP_mean_murton(audio_file)\n",
    "    if 'PP_CPP_M2' in selected_features:\n",
    "        extracted_features['PP_CPP_M2'] = PP_CPP_median_murton(audio_file)\n",
    "    if 'PP_CPP_SD_M' in selected_features:\n",
    "        extracted_features['PP_CPP_SD_M'] = PP_CPP_sd_murton(audio_file)\n",
    "        \n",
    "    if 'PP_DUR_WP' in selected_features:\n",
    "        extracted_features['PP_DUR_WP'] = PP_duration_with_pauses(audio_file, silence_threshold)\n",
    "    if 'PP_DUR_WOP' in selected_features:\n",
    "        extracted_features['PP_DUR_WOP'] = PP_duration_without_pauses(audio_file, silence_threshold, min_silence_duration)\n",
    "\n",
    "    if 'PP_JIT' in selected_features:\n",
    "        jitter_values = PP_jitter(audio_file, f0_min=f0_min, f0_max=f0_max) \n",
    "        for feature in jitter_feature_selection:\n",
    "            if feature in jitter_feature_indices:\n",
    "                feature_idx = jitter_feature_indices[feature]            \n",
    "                extracted_features[f'PP_JIT_{feature}'] = jitter_values[feature_idx]  \n",
    "    if 'PP_JIT_M' in selected_features:\n",
    "        jitter_values = PP_jitter_murton(audio_file, segment_length=segment_length, f0_min=f0_min, f0_max=f0_max) \n",
    "        for feature in jitter_feature_selection:\n",
    "            if feature in jitter_feature_indices:\n",
    "                feature_idx = jitter_feature_indices[feature]            \n",
    "                extracted_features[f'PP_JIT_M_{feature}'] = jitter_values[feature_idx]    \n",
    "                    \n",
    "    if 'PP_SHI' in selected_features:\n",
    "        shimmer_values = PP_shimmer(audio_file, f0_min=f0_min, f0_max=f0_max) \n",
    "        for feature in shimmer_feature_selection:\n",
    "            if feature in shimmer_feature_indices:\n",
    "                feature_idx = shimmer_feature_indices[feature]            \n",
    "                extracted_features[f'PP_SHI_{feature}'] = shimmer_values[feature_idx]\n",
    "    if 'PP_SHI_M' in selected_features:\n",
    "        shimmer_values = PP_shimmer_murton(audio_file, segment_length=segment_length, f0_min=f0_min, f0_max=f0_max) \n",
    "        for feature in shimmer_feature_selection:\n",
    "            if feature in shimmer_feature_indices:\n",
    "                feature_idx = shimmer_feature_indices[feature]            \n",
    "                extracted_features[f'PP_SHI_M_{feature}'] = shimmer_values[feature_idx]\n",
    "\n",
    "    if 'PP_MFC' in selected_features:\n",
    "        mfc_values = PP_MFCC(audio_file, num_coefficients=num_coefficients)\n",
    "        for i in range(num_coefficients):\n",
    "            for feature in mfc_feature_selection:\n",
    "                if feature in mfc_feature_indices:\n",
    "                    feature_idx = mfc_feature_indices[feature]\n",
    "                    extracted_features[f'PP_MFC_{i+1}_{feature}'] = mfc_values[i+(num_coefficients*feature_idx)]\n",
    "\n",
    "    if 'PP_F_MEA' in selected_features:\n",
    "        mean_formant_values = PP_formants_mean(audio_file, time_step=time_step, max_frequency=max_frequency, num_formants=num_formants)\n",
    "        for i in range(len(mean_formant_values)): \n",
    "            extracted_features[f'PP_F{i+1}_MEA'] = mean_formant_values[i]\n",
    "    if 'PP_F_MED' in selected_features:\n",
    "        median_formant_values = PP_formants_median(audio_file, time_step=time_step, max_frequency=max_frequency, num_formants=num_formants)\n",
    "        for i in range(len(median_formant_values)): \n",
    "            extracted_features[f'PP_F{i+1}_MED'] = median_formant_values[i]            \n",
    "    if 'PP_F_SD' in selected_features:\n",
    "        sd_formant_values = PP_formants_sd(audio_file, time_step=time_step, max_frequency=max_frequency, num_formants=num_formants)\n",
    "        for i in range(len(sd_formant_values)): \n",
    "            extracted_features[f'PP_F{i+1}_SD'] = sd_formant_values[i]  \n",
    "\n",
    "    if 'DV_PRO' in selected_features:\n",
    "        prosody_features = DV_prosody(audio_file)\n",
    "        for feature in prosody_features.columns:\n",
    "            extracted_features[f'DV_PRO_{feature}'] = prosody_features[feature].values[0]\n",
    "    if 'DV_PHO' in selected_features: \n",
    "        phonation_features = DV_phonation(audio_file)\n",
    "        for feature in phonation_features.columns:\n",
    "            extracted_features[f'DV_PHO_{feature}'] = phonation_features[feature].values[0]     \n",
    "\n",
    "    return extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_SPN(audio_file, selected_features, f0_min, f0_max, silence_threshold, min_silence_duration, segment_length, num_coefficients, time_step, max_frequency, num_formants):\n",
    "    extracted_features = {}\n",
    "    \n",
    "    if 'PP_F0' in selected_features:\n",
    "        extracted_features['PP_F0'] = PP_f0_median(audio_file, f0_min=f0_min, f0_max=f0_max)    \n",
    "    if 'PP_F0_M' in selected_features:\n",
    "        extracted_features['PP_F0_M'] = PP_f0_median_murton(audio_file, f0_min=f0_min, f0_max=f0_max)  \n",
    "    if 'PP_F0_SD' in selected_features:\n",
    "        extracted_features['PP_F0_SD'] = PP_f0_sd(audio_file, f0_min=f0_min, f0_max=f0_max)\n",
    "    if 'PP_F0_SD_M' in selected_features:\n",
    "        extracted_features['PP_F0_SD_M'] = PP_f0_sd_murton(audio_file, f0_min=f0_min, f0_max=f0_max)\n",
    "        \n",
    "    if 'PP_CPP_M' in selected_features:\n",
    "        extracted_features['PP_CPP_M'] = PP_CPP_mean_murton(audio_file)\n",
    "    if 'PP_CPP_M2' in selected_features:\n",
    "        extracted_features['PP_CPP_M2'] = PP_CPP_median_murton(audio_file)\n",
    "    if 'PP_CPP_SD_M' in selected_features:\n",
    "        extracted_features['PP_CPP_SD_M'] = PP_CPP_sd_murton(audio_file)\n",
    "        \n",
    "    if 'PP_DUR_WP' in selected_features:\n",
    "        extracted_features['PP_DUR_WP'] = PP_duration_with_pauses(audio_file, silence_threshold)\n",
    "    if 'PP_DUR_WOP' in selected_features:\n",
    "        extracted_features['PP_DUR_WOP'] = PP_duration_without_pauses(audio_file, silence_threshold, min_silence_duration)\n",
    "\n",
    "    if 'PP_JIT' in selected_features:\n",
    "        jitter_values = PP_jitter(audio_file, f0_min=f0_min, f0_max=f0_max) \n",
    "        for feature in jitter_feature_selection:\n",
    "            if feature in jitter_feature_indices:\n",
    "                feature_idx = jitter_feature_indices[feature]            \n",
    "                extracted_features[f'PP_JIT_{feature}'] = jitter_values[feature_idx]  \n",
    "    if 'PP_JIT_M' in selected_features:\n",
    "        jitter_values = PP_jitter_murton(audio_file, segment_length=segment_length, f0_min=f0_min, f0_max=f0_max) \n",
    "        for feature in jitter_feature_selection:\n",
    "            if feature in jitter_feature_indices:\n",
    "                feature_idx = jitter_feature_indices[feature]            \n",
    "                extracted_features[f'PP_JIT_M_{feature}'] = jitter_values[feature_idx]    \n",
    "                    \n",
    "    if 'PP_SHI' in selected_features:\n",
    "        shimmer_values = PP_shimmer(audio_file, f0_min=f0_min, f0_max=f0_max) \n",
    "        for feature in shimmer_feature_selection:\n",
    "            if feature in shimmer_feature_indices:\n",
    "                feature_idx = shimmer_feature_indices[feature]            \n",
    "                extracted_features[f'PP_SHI_{feature}'] = shimmer_values[feature_idx]\n",
    "    if 'PP_SHI_M' in selected_features:\n",
    "        shimmer_values = PP_shimmer_murton(audio_file, segment_length=segment_length, f0_min=f0_min, f0_max=f0_max) \n",
    "        for feature in shimmer_feature_selection:\n",
    "            if feature in shimmer_feature_indices:\n",
    "                feature_idx = shimmer_feature_indices[feature]            \n",
    "                extracted_features[f'PP_SHI_M_{feature}'] = shimmer_values[feature_idx]\n",
    "\n",
    "    if 'PP_MFC' in selected_features:\n",
    "        mfc_values = PP_MFCC(audio_file, num_coefficients=num_coefficients)\n",
    "        for i in range(num_coefficients):\n",
    "            for feature in mfc_feature_selection:\n",
    "                if feature in mfc_feature_indices:\n",
    "                    feature_idx = mfc_feature_indices[feature]\n",
    "                    extracted_features[f'PP_MFC_{i+1}_{feature}'] = mfc_values[i+(num_coefficients*feature_idx)]\n",
    "\n",
    "    if 'PP_F_MEA' in selected_features:\n",
    "        mean_formant_values = PP_formants_mean(audio_file, time_step=time_step, max_frequency=max_frequency, num_formants=num_formants)\n",
    "        for i in range(len(mean_formant_values)): \n",
    "            extracted_features[f'PP_F{i+1}_MEA'] = mean_formant_values[i]\n",
    "    if 'PP_F_MED' in selected_features:\n",
    "        median_formant_values = PP_formants_median(audio_file, time_step=time_step, max_frequency=max_frequency, num_formants=num_formants)\n",
    "        for i in range(len(median_formant_values)): \n",
    "            extracted_features[f'PP_F{i+1}_MED'] = median_formant_values[i]            \n",
    "    if 'PP_F_SD' in selected_features:\n",
    "        sd_formant_values = PP_formants_sd(audio_file, time_step=time_step, max_frequency=max_frequency, num_formants=num_formants)\n",
    "        for i in range(len(sd_formant_values)): \n",
    "            extracted_features[f'PP_F{i+1}_SD'] = sd_formant_values[i]  \n",
    "\n",
    "    if 'DV_PHO' in selected_features: \n",
    "        phonation_features = DV_phonation(audio_file)\n",
    "        for feature in phonation_features.columns:\n",
    "            extracted_features[f'DV_PHO_{feature}'] = phonation_features[feature].values[0]     \n",
    "\n",
    "            \n",
    "    return extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_MPT(audio_file, selected_features, silence_threshold, min_silence_duration):\n",
    "    extracted_features = {}\n",
    "    \n",
    "    if 'PP_DUR_WP' in selected_features:\n",
    "        extracted_features['PP_DUR_WP'] = PP_duration_with_pauses(audio_file, silence_threshold)\n",
    "    if 'PP_DUR_WOP' in selected_features:\n",
    "        extracted_features['PP_DUR_WOP'] = PP_duration_without_pauses(audio_file, silence_threshold, min_silence_duration)\n",
    "            \n",
    "    return extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_files_VOW(directory, selected_features, segment_length, f0_min, f0_max, point_step, time_step, max_frequency, num_formants):\n",
    "    patient_dfs = {}\n",
    "\n",
    "    files = [file for d in directory for file in d.rglob('*') if file.is_file()]\n",
    "\n",
    "    for file in files:\n",
    "        filename = file.stem.replace(\"_pre\", \"\")\n",
    "        parts = filename.split(\"_\")\n",
    "        if len(parts) != 4:\n",
    "            print(f\"Unexpected named audio file: {file}\")\n",
    "            continue\n",
    "\n",
    "        patient_id, day, exercise, take_letter = parts\n",
    "\n",
    "        features = {}\n",
    "        file_path = str(file)\n",
    "        \n",
    "        if exercise == 'VOW':\n",
    "            if directory == best_segments_dir:\n",
    "                if file_path[-1].isdigit(): \n",
    "                    continue ## we do not analyze the best segment of the entire vowel exercise, only of the best segments\n",
    "                if file_path[-1].isalpha():\n",
    "                    features = extract_features_VOW(\n",
    "                        file_path, selected_features, \n",
    "                        f0_min, f0_max,\n",
    "                        point_step, time_step, max_frequency, num_formants)\n",
    "            else:\n",
    "                features = extract_features_VOW(\n",
    "                    file_path, selected_features, \n",
    "                    segment_length, \n",
    "                    f0_min, f0_max,\n",
    "                    point_step, time_step, max_frequency, num_formants)\n",
    "        \n",
    "        if features:    \n",
    "            df_entry = {'day': int(day), **features}       \n",
    "            df_key = (patient_id, take_letter, exercise)\n",
    "            if df_key not in patient_dfs:\n",
    "                patient_dfs[df_key] = pd.DataFrame(columns=['day'] + list(features.keys()))\n",
    "            patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
    "        \n",
    "        for key, df in patient_dfs.items():\n",
    "            patient_dfs[key] = df.sort_values(by='day', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        for (patient_id, take_letter, exercise), df in patient_dfs.items():\n",
    "            file_name = f\"{patient_id}_{exercise}_{take_letter}.csv\"\n",
    "            file_path = features_dir / exercise / patient_id / file_name\n",
    "\n",
    "            df.to_csv(file_path, index=False)\n",
    "\n",
    "\n",
    "def process_audio_files_SEN(directory, selected_features, f0_min, f0_max, silence_threshold, min_silence_duration, segment_length, num_coefficients, time_step, max_frequency, num_formants):\n",
    "    patient_dfs = {}\n",
    "\n",
    "    files = [file for d in directory for file in d.rglob('*') if file.is_file()]\n",
    "\n",
    "    for file in files:\n",
    "        filename = file.stem.replace(\"_pre\", \"\")\n",
    "        parts = filename.split(\"_\")\n",
    "        if len(parts) != 4:\n",
    "            print(f\"Unexpected named audio file: {file}\")\n",
    "            continue\n",
    "\n",
    "        patient_id, day, exercise, take_letter = parts\n",
    "        \n",
    "        features = {}\n",
    "        file_path = str(file)\n",
    "        \n",
    "        if exercise == 'SEN':\n",
    "            features = extract_features_SEN(\n",
    "                file_path, selected_features, \n",
    "                f0_min, f0_max, \n",
    "                silence_threshold, min_silence_duration, \n",
    "                segment_length,\n",
    "                num_coefficients,\n",
    "                time_step, max_frequency, num_formants)\n",
    "            \n",
    "        if features:\n",
    "            df_entry = {'day': int(day), **features}    \n",
    "            df_key = (patient_id, take_letter, exercise)\n",
    "            if df_key not in patient_dfs:\n",
    "                patient_dfs[df_key] = pd.DataFrame(columns=['day'] + list(features.keys()))\n",
    "            patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
    "        \n",
    "        for key, df in patient_dfs.items():\n",
    "            patient_dfs[key] = df.sort_values(by='day', ascending=True).reset_index(drop=True)\n",
    "            \n",
    "        for (patient_id, take_letter, exercise), df in patient_dfs.items():\n",
    "            file_name = f\"{patient_id}_{exercise}_{take_letter}.csv\"\n",
    "            file_path = features_dir / exercise / patient_id / file_name\n",
    "\n",
    "            df.to_csv(file_path, index=False)\n",
    "  \n",
    "\n",
    "def process_audio_files_SPN(directory, selected_features, f0_min, f0_max, silence_threshold, min_silence_duration, segment_length, num_coefficients, time_step, max_frequency, num_formants):\n",
    "    patient_dfs = {}\n",
    "\n",
    "    files = [file for d in directory for file in d.rglob('*') if file.is_file()]\n",
    "\n",
    "    for file in files:\n",
    "        filename = file.stem.replace(\"_pre\", \"\")\n",
    "        parts = filename.split(\"_\")\n",
    "        if len(parts) != 4:\n",
    "            print(f\"Unexpected named audio file: {file}\")\n",
    "            continue\n",
    "\n",
    "        patient_id, day, exercise, take_letter = parts\n",
    "        \n",
    "        features = {}\n",
    "        file_path = str(file)\n",
    "        \n",
    "        if exercise == 'SPN':\n",
    "            features = extract_features_SPN(\n",
    "                file_path, selected_features, \n",
    "                f0_min, f0_max, \n",
    "                silence_threshold, min_silence_duration, \n",
    "                segment_length,\n",
    "                num_coefficients,\n",
    "                time_step, max_frequency, num_formants)\n",
    "            \n",
    "        if features:\n",
    "            df_entry = {'day': int(day), **features}    \n",
    "            df_key = (patient_id, take_letter, exercise)\n",
    "            if df_key not in patient_dfs:\n",
    "                patient_dfs[df_key] = pd.DataFrame(columns=['day'] + list(features.keys()))\n",
    "            patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
    "        \n",
    "        for key, df in patient_dfs.items():\n",
    "            patient_dfs[key] = df.sort_values(by='day', ascending=True).reset_index(drop=True)\n",
    "            \n",
    "        for (patient_id, take_letter, exercise), df in patient_dfs.items():\n",
    "            file_name = f\"{patient_id}_{exercise}_{take_letter}.csv\"\n",
    "            file_path = features_dir / exercise / patient_id / file_name\n",
    "\n",
    "            df.to_csv(file_path, index=False)\n",
    "          \n",
    "\n",
    "def process_audio_files_MPT(directory, selected_features, silence_threshold, min_silence_duration):\n",
    "    patient_dfs = {}\n",
    "\n",
    "    files = [file for d in directory for file in d.rglob('*') if file.is_file()]\n",
    "\n",
    "    for file in files:\n",
    "        filename = file.stem.replace(\"_pre\", \"\")\n",
    "        parts = filename.split(\"_\")\n",
    "        if len(parts) != 4:\n",
    "            print(f\"Unexpected named audio file: {file}\")\n",
    "            continue\n",
    "\n",
    "        patient_id, day, exercise, take_letter = parts\n",
    "\n",
    "        features = {}\n",
    "        file_path = str(file)\n",
    "        \n",
    "        if exercise == 'MPT':\n",
    "            features = extract_features_MPT(\n",
    "                file_path, selected_features, \n",
    "                silence_threshold, min_silence_duration)\n",
    "            \n",
    "        if features:            \n",
    "            df_entry = {'day': int(day), **features}    \n",
    "            df_key = (patient_id, take_letter, exercise)\n",
    "            if df_key not in patient_dfs:\n",
    "                patient_dfs[df_key] = pd.DataFrame(columns=['day'] + list(features.keys()))\n",
    "            patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n",
    "            \n",
    "        for key, df in patient_dfs.items():\n",
    "            patient_dfs[key] = df.sort_values(by='day', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        for (patient_id, take_letter, exercise), df in patient_dfs.items():\n",
    "            file_name = f\"{patient_id}_{exercise}_{take_letter}.csv\"\n",
    "            file_path = features_dir / exercise / patient_id / file_name\n",
    "\n",
    "            df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 68.7659105 ,  12.65465804, -74.90310369, 120.38751737,\n",
      "       -48.63423589, -12.44445287,  28.10525161, -16.79323548,\n",
      "       -32.40317417, -28.23961292, -14.31534221, -10.57531583]), array([214.77064327, 118.59027699,  88.68658585,  58.73145772,\n",
      "        43.7876108 ,  41.3292052 ,  39.27796648,  33.11949595,\n",
      "        35.59467704,  33.6377141 ,  28.28252499,  28.07149195]), array([-0.21906361, -0.5329607 ,  0.99161556,  0.21900002, -0.15352525,\n",
      "       -0.23828549, -0.29958751, -0.04953513, -0.15169581, -0.32526049,\n",
      "       -0.18595388,  0.03702007]), array([-1.23498579,  0.22106314,  0.82004715,  0.106628  , -0.0163785 ,\n",
      "        0.73122183,  0.14849327,  0.57849406, -0.10109907,  0.27321899,\n",
      "        0.41948745,  0.34956745]), array([ 98.63219593,  29.24739243, -96.17525806, 115.96051982,\n",
      "       -45.94531555,  -9.61451916,  30.26103315, -15.96306503,\n",
      "       -30.51886259, -26.04192044, -12.65120278, -10.44117618]), array([-567.6616402 , -377.57835778, -306.63730324,  -76.57888978,\n",
      "       -227.49353556, -187.78771017, -118.49224982, -145.61406975,\n",
      "       -150.95529846, -162.59860474, -140.60487354, -119.19448989]), array([431.86591407, 310.1299689 , 268.72581844, 340.59183384,\n",
      "        96.70545447, 167.62340367, 150.9910106 , 107.75300158,\n",
      "        80.61401648,  93.44103927,  96.80532745, 103.92875996])]\n",
      "        F0avg      F0std       F0max      F0min    F0skew    F0kurt  \\\n",
      "0  113.658051  15.449023  190.095581  73.450729  1.404588  2.567388   \n",
      "\n",
      "   F0tiltavg   F0mseavg   F0tiltstd   F0msestd  ...  skwdurpause  \\\n",
      "0  -39.54886  11.806039  143.177742  23.004559  ...     2.054678   \n",
      "\n",
      "   kurtosisdurpause  maxdurpause  mindurpause       PVU        PU       UVU  \\\n",
      "0          4.190011         2.91         0.15  3.141094  7.901168  0.397548   \n",
      "\n",
      "        VVU        VP        UP  \n",
      "0  0.602452  0.191797  0.126564  \n",
      "\n",
      "[1 rows x 103 columns]\n",
      "    avg DF0  avg DDF0  avg Jitter  avg Shimmer    avg apq   avg ppq  \\\n",
      "0 -0.047275 -0.012555    2.609172     5.593504  32.693427  2.789502   \n",
      "\n",
      "    avg logE   std DF0   std DDF0  std Jitter  ...  skewness apq  \\\n",
      "0 -34.691366  8.841157  13.312836     4.06586  ...       1.26686   \n",
      "\n",
      "   skewness ppq  skewness logE  kurtosis DF0  kurtosis DDF0  kurtosis Jitter  \\\n",
      "0      2.564321       -0.41534     13.104349       9.047877        17.229533   \n",
      "\n",
      "   kurtosis Shimmer  kurtosis apq  kurtosis ppq  kurtosis logE  \n",
      "0         17.405645      2.239387      8.126125       0.217448  \n",
      "\n",
      "[1 rows x 28 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_895/1209052169.py:82: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  patient_dfs[df_key] = pd.concat([patient_dfs[df_key], pd.DataFrame([df_entry])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "dir_to_run_VOW = [\n",
    "    processed_dir,\n",
    "    segments_dir,\n",
    "    # best_segments_dir, ## will not use the best segments for now, since I might use the middle of a vowel segment Murton2023\n",
    "]\n",
    "dir_to_run_SEN = [processed_dir, segments_dir]\n",
    "dir_to_run_SPN = [processed_dir, segments_dir]\n",
    "dir_to_run_MPT = [processed_dir, segments_dir]\n",
    "\n",
    "process_audio_files_VOW(\n",
    "    directory=dir_to_run_VOW,\n",
    "    selected_features=selected_features_dict_VOW,\n",
    "    segment_length=1.0,\n",
    "    f0_min=60, f0_max=300,\n",
    "    point_step=0.0025, time_step=0.01, max_frequency=5000, num_formants=5)\n",
    "\n",
    "# process_audio_files_SEN(\n",
    "#     directory=dir_to_run_SEN,\n",
    "#     selected_features=selected_features_dict_SEN,\n",
    "#     f0_min=60, f0_max=300,\n",
    "#     silence_threshold=50, min_silence_duration=0.5,\n",
    "#     num_coefficients=12,\n",
    "#     segment_length=1.0,\n",
    "#     time_step=0.01, max_frequency=5000, num_formants=5)\n",
    "\n",
    "# process_audio_files_SPN(\n",
    "#     directory=dir_to_run_SPN,\n",
    "#     selected_features=selected_features_dict_SPN,\n",
    "#     f0_min=60, f0_max=300,\n",
    "#     silence_threshold=50, min_silence_duration=0.5,\n",
    "#     num_coefficients=12,\n",
    "#     segment_length=1.0,\n",
    "#     time_step=0.01, max_frequency=5000, num_formants=5)\n",
    "\n",
    "# process_audio_files_MPT(\n",
    "#     directory=dir_to_run_MPT,\n",
    "#     selected_features=selected_features_dict_MPT,\n",
    "#     silence_threshold=50, min_silence_duration=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rp2",
   "language": "python",
   "name": "rp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
